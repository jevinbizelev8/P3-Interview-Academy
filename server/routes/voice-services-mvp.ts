import { Router } from 'express';
import { sealionService } from '../services/sealion';
import { requireAuth } from '../auth-simple';
import multer from 'multer';
import * as fs from 'fs';

const router = Router();

// Configure multer for file uploads
const upload = multer({ 
  dest: '/tmp/uploads/',
  limits: { fileSize: 10 * 1024 * 1024 }, // 10MB limit
  fileFilter: (req, file, cb) => {
    const allowedTypes = ['audio/wav', 'audio/webm', 'audio/mp3', 'audio/mp4', 'audio/ogg', 'audio/mpeg'];
    if (allowedTypes.includes(file.mimetype) || file.mimetype.startsWith('audio/')) {
      cb(null, true);
    } else {
      cb(new Error('Invalid audio file type'));
    }
  }
});

// Ensure uploads directory exists
if (!fs.existsSync('/tmp/uploads')) {
  fs.mkdirSync('/tmp/uploads', { recursive: true });
}

// Voice service status
router.get('/health', async (req, res) => {
  try {
    const status = {
      status: 'healthy',
      services: {
        browserTTS: true, // Web Speech API
        browserSTT: true, // Web Speech API
        sealion: true, // For text processing
        translation: true // SeaLion translation
      },
      features: {
        tts: 'Browser Web Speech API',
        stt: 'Browser Web Speech API',
        translation: 'SeaLion AI',
        languages: 10
      },
      timestamp: new Date().toISOString()
    };
    res.json(status);
  } catch (error) {
    res.status(500).json({ error: 'Voice services health check failed' });
  }
});

// Voice service configuration
router.get('/config', async (req, res) => {
  try {
    const config = {
      supportedLanguages: [
        { code: 'en', name: 'English', localName: 'English', browserSupport: true },
        { code: 'ms', name: 'Bahasa Malaysia', localName: 'Bahasa Malaysia', browserSupport: true },
        { code: 'id', name: 'Bahasa Indonesia', localName: 'Bahasa Indonesia', browserSupport: true },
        { code: 'th', name: 'Thai', localName: 'à¹„à¸—à¸¢', browserSupport: true },
        { code: 'vi', name: 'Vietnamese', localName: 'Tiáº¿ng Viá»‡t', browserSupport: true },
        { code: 'fil', name: 'Filipino', localName: 'Filipino', browserSupport: true },
        { code: 'my', name: 'Myanmar', localName: 'á€™á€¼á€”á€ºá€™á€¬', browserSupport: false },
        { code: 'km', name: 'Khmer', localName: 'ááŸ’á˜áŸ‚áš', browserSupport: false },
        { code: 'lo', name: 'Lao', localName: 'àº¥àº²àº§', browserSupport: false },
        { code: 'zh-cn', name: 'Simplified Chinese', localName: 'ç®€ä½“ä¸­æ–‡', browserSupport: true },
        { code: 'zh-tw', name: 'Traditional Chinese', localName: 'ç¹é«”ä¸­æ–‡', browserSupport: true },
        { code: 'zh-hk', name: 'Chinese (Hong Kong)', localName: 'ä¸­æ–‡ (é¦™æ¸¯)', browserSupport: true }
      ],
      ttsVoices: {
        en: ['en-US-Standard-A', 'en-US-Standard-B', 'en-US-Standard-C', 'en-US-Standard-D'],
        ms: ['ms-MY-Standard-A', 'ms-MY-Standard-B'],
        id: ['id-ID-Standard-A', 'id-ID-Standard-B'],
        th: ['th-TH-Standard-A', 'th-TH-Standard-B'],
        vi: ['vi-VN-Standard-A', 'vi-VN-Standard-B'],
        fil: ['fil-PH-Standard-A', 'fil-PH-Standard-B'],
        'zh-cn': ['zh-CN-Standard-A', 'zh-CN-Standard-B', 'zh-CN-Standard-C', 'zh-CN-Standard-D'],
        'zh-tw': ['zh-TW-Standard-A', 'zh-TW-Standard-B', 'zh-TW-Standard-C'],
        'zh-hk': ['zh-HK-Standard-A', 'zh-HK-Standard-B']
      },
      browserVoices: {
        en: ['Google US English', 'Microsoft David Desktop', 'Microsoft Zira Desktop'],
        ms: ['Google Bahasa Malaysia', 'Microsoft Rizwan Desktop'],
        id: ['Google Bahasa Indonesia', 'Microsoft Andika Desktop'],
        th: ['Google à¹„à¸—à¸¢', 'Microsoft Pattara Desktop'],
        vi: ['Google Tiáº¿ng Viá»‡t', 'Microsoft An Desktop'],
        fil: ['Google Filipino', 'Microsoft Angelo Desktop'],
        'zh-cn': ['Google æ™®é€šè¯ (ä¸­å›½å¤§é™†)', 'Microsoft Yaoyao Desktop', 'Microsoft Kangkang Desktop'],
        'zh-tw': ['Google åœ‹èª (å°ç£)', 'Microsoft Zhiwei Desktop', 'Microsoft Yating Desktop'],
        'zh-hk': ['Google ç²µèª (é¦™æ¸¯)', 'Microsoft Tracy Desktop', 'Microsoft Danny Desktop']
      },
      sttModels: ['browser-speech-api', 'whisper-1'],
      maxFileSize: '10MB',
      supportedFormats: ['wav', 'mp3', 'm4a', 'webm', 'ogg'],
      freeServices: {
        browserTTS: 'Unlimited',
        browserSTT: 'Unlimited',
        translation: 'Unlimited via SeaLion'
      }
    };
    res.json(config);
  } catch (error) {
    res.status(500).json({ error: 'Failed to get voice configuration' });
  }
});

// Text-to-Speech endpoint (processes text for browser TTS)
router.post('/tts', requireAuth, async (req, res) => {
  try {
    const { text, language = 'en', voice, rate = 1.0, pitch = 1.0 } = req.body;
    
    if (!text) {
      return res.status(400).json({ error: 'Text is required' });
    }

    // Use SeaLion for text processing and optimization
    const processedText = await sealionService.generateResponse({
      messages: [{
        role: 'user',
        content: `Optimize this text for speech synthesis in ${language}: "${text}". 
        Add natural pauses, correct pronunciation hints, and ensure it flows well when spoken. 
        Return only the optimized text, no explanations.`
      }],
      maxTokens: 500,
      temperature: 0.3
    });

    // Get available browser voices for the language
    const availableVoices = getBrowserVoices(language);
    const selectedVoice = voice || availableVoices[0] || 'default';

    const ttsResponse = {
      success: true,
      text: processedText,
      originalText: text,
      language,
      voice: selectedVoice,
      availableVoices,
      rate,
      pitch,
      duration: estimateDuration(processedText),
      method: 'browser-speech-api',
      instructions: {
        useBrowserTTS: true,
        voiceName: selectedVoice,
        rate: rate,
        pitch: pitch,
        language: language
      },
      timestamp: new Date().toISOString()
    };

    res.json(ttsResponse);
  } catch (error) {
    console.error('TTS Error:', error);
    res.status(500).json({ 
      error: 'TTS processing failed',
      details: error instanceof Error ? error.message : 'Unknown error'
    });
  }
});

// Speech-to-Text endpoint (actual transcription using OpenAI Whisper)
router.post('/stt', requireAuth, upload.single('audio'), async (req, res) => {
  try {
    console.log('ğŸ” STT ENDPOINT: Request received');
    console.log('ğŸ” STT ENDPOINT: Content-Type:', req.headers['content-type']);
    console.log('ğŸ” STT ENDPOINT: Body:', req.body);
    console.log('ğŸ” STT ENDPOINT: File:', req.file ? `${req.file.filename} (${req.file.size} bytes)` : 'none');

    // Handle audio file upload
    if (req.file) {
      console.log('ğŸ§ STT ENDPOINT: Audio file received');
      const language = req.body.language || 'en';
      const model = req.body.model || 'whisper-1';
      
      console.log(`ğŸ” STT ENDPOINT: File: ${req.file.originalname}, Size: ${req.file.size} bytes, Language: ${language}, Model: ${model}`);
      
      try {
        // Import OpenAI service dynamically
        const { getOpenAIService } = await import('../services/openai-service');
        
        console.log('ğŸ” STT ENDPOINT: Calling OpenAI Whisper API...');
        
        // Use the file path directly for OpenAI API - more reliable than Buffer conversion
        const { createReadStream } = await import('fs');
        const fileStream = createReadStream(req.file.path);
        
        // Use OpenAI Whisper for transcription
        const transcription = await getOpenAIService().transcribeAudio(fileStream, {
          language: language,
          model: model,
          filename: req.file.originalname || 'recording.wav'
        });
        
        console.log(`âœ… STT ENDPOINT: Whisper transcription successful: "${transcription}"`);
        
        // Clean up uploaded file
        fs.unlinkSync(req.file.path);
        
        const sttResponse = {
          success: true,
          transcription: transcription,
          originalTranscription: transcription,
          language: language,
          model: model,
          confidence: 0.9, // OpenAI Whisper provides high confidence
          duration: 0, // Would need to calculate from audio
          method: 'openai-whisper',
          timestamp: new Date().toISOString()
        };

        res.json(sttResponse);
      } catch (transcriptionError) {
        console.error('âŒ STT ENDPOINT: Transcription error:', transcriptionError);
        
        // Clean up uploaded file on error
        if (req.file && fs.existsSync(req.file.path)) {
          fs.unlinkSync(req.file.path);
        }
        
        throw transcriptionError;
      }
    } else {
      // Fallback: provide configuration for browser STT
      console.log('ğŸ” STT ENDPOINT: No audio file, returning browser STT config');
      const { language = 'en', continuous = false, interimResults = true } = req.body;

      const sttResponse = {
        success: true,
        language,
        continuous,
        interimResults,
        method: 'browser-speech-api',
        instructions: {
          useBrowserSTT: true,
          language: language,
          continuous: continuous,
          interimResults: interimResults,
          maxAlternatives: 1
        },
        supportedLanguages: getSupportedSTTLanguages(),
        timestamp: new Date().toISOString()
      };

      res.json(sttResponse);
    }
  } catch (error) {
    console.error('âŒ STT ENDPOINT Error:', error);
    res.status(500).json({ 
      success: false,
      error: 'STT processing failed',
      details: error instanceof Error ? error.message : 'Unknown error'
    });
  }
});

// Translation endpoint
router.post('/translate', requireAuth, async (req, res) => {
  try {
    const { text, targetLanguage, sourceLanguage = 'en' } = req.body;
    
    if (!text || !targetLanguage) {
      return res.status(400).json({ error: 'Text and target language are required' });
    }

    // Use SeaLion for translation
    const translation = await sealionService.generateResponse({
      messages: [{
        role: 'user',
        content: `Translate this text from ${sourceLanguage} to ${targetLanguage}: "${text}". 
        Ensure the translation is natural, culturally appropriate, and maintains the original meaning. 
        Return only the translation, no explanations.`
      }],
      maxTokens: 1000,
      temperature: 0.3
    });

    const translationResponse = {
      success: true,
      originalText: text,
      translatedText: translation,
      sourceLanguage,
      targetLanguage,
      method: 'sealion-ai',
      timestamp: new Date().toISOString()
    };

    res.json(translationResponse);
  } catch (error) {
    console.error('Translation Error:', error);
    res.status(500).json({ 
      error: 'Translation failed',
      details: error instanceof Error ? error.message : 'Unknown error'
    });
  }
});

// Voice quality recommendations
router.post('/quality-recommendations', requireAuth, async (req, res) => {
  try {
    const { audioMetrics, language = 'en' } = req.body;

    const recommendations = generateQualityRecommendations(audioMetrics, language);

    res.json({
      success: true,
      recommendations,
      language,
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    console.error('Quality Recommendations Error:', error);
    res.status(500).json({ 
      error: 'Quality recommendations failed',
      details: error instanceof Error ? error.message : 'Unknown error'
    });
  }
});

// Browser voice detection endpoint
router.get('/browser-voices', async (req, res) => {
  try {
    const { language } = req.query;
    
    const voices = getBrowserVoices(language as string || 'en');
    
    res.json({
      success: true,
      voices,
      language: language || 'en',
      totalVoices: voices.length,
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    console.error('Browser Voices Error:', error);
    res.status(500).json({ 
      error: 'Failed to get browser voices',
      details: error instanceof Error ? error.message : 'Unknown error'
    });
  }
});

// Helper functions
function getBrowserVoices(language: string): string[] {
  const voiceMap: Record<string, string[]> = {
    'en': ['Google US English', 'Microsoft David Desktop', 'Microsoft Zira Desktop', 'Samantha'],
    'ms': ['Google Bahasa Malaysia', 'Microsoft Rizwan Desktop'],
    'id': ['Google Bahasa Indonesia', 'Microsoft Andika Desktop'],
    'th': ['Google à¹„à¸—à¸¢', 'Microsoft Pattara Desktop'],
    'vi': ['Google Tiáº¿ng Viá»‡t', 'Microsoft An Desktop'],
    'fil': ['Google Filipino', 'Microsoft Angelo Desktop'],
    'zh-cn': ['Google æ™®é€šè¯ (ä¸­å›½å¤§é™†)', 'Microsoft Yaoyao Desktop', 'Microsoft Kangkang Desktop'],
    'zh-tw': ['Google åœ‹èª (å°ç£)', 'Microsoft Zhiwei Desktop', 'Microsoft Yating Desktop'],
    'zh-hk': ['Google ç²µèª (é¦™æ¸¯)', 'Microsoft Tracy Desktop', 'Microsoft Danny Desktop']
  };
  return voiceMap[language] || ['Default Voice'];
}

function getSupportedSTTLanguages(): string[] {
  return [
    'en-US', 'en-GB', 'en-AU', 'en-CA', 'en-IN',
    'ms-MY', 'id-ID', 'th-TH', 'vi-VN', 'fil-PH',
    'zh-CN', 'zh-TW', 'zh-HK', 'ja-JP', 'ko-KR'
  ];
}

function estimateDuration(text: string): number {
  // Rough estimate: 150 words per minute
  const words = text.split(' ').length;
  return Math.ceil((words / 150) * 60);
}

function generateQualityRecommendations(audioMetrics: any, language: string): string[] {
  const recommendations = [];
  
  if (audioMetrics) {
    if (audioMetrics.volume < 0.1) {
      recommendations.push("Audio volume is too low. Please speak closer to the microphone.");
    } else if (audioMetrics.volume > 0.9) {
      recommendations.push("Audio volume is too high. Please speak further from the microphone.");
    }
    
    if (audioMetrics.duration < 2) {
      recommendations.push("Audio is too short. Please speak for at least 2-3 seconds.");
    }
    
    if (audioMetrics.noise > 0.3) {
      recommendations.push("Background noise detected. Please find a quieter environment.");
    }
  }
  
  // Language-specific recommendations
  const languageTips: Record<string, string[]> = {
    'en': [
      "Speak clearly and at a moderate pace",
      "Pause briefly between sentences",
      "Use proper pronunciation for technical terms"
    ],
    'ms': [
      "Bercakap dengan jelas dan perlahan-lahan",
      "Gunakan sebutan yang betul untuk istilah teknikal",
      "Jeda sebentar antara ayat"
    ],
    'id': [
      "Berbicara dengan jelas dan perlahan",
      "Gunakan pengucapan yang benar untuk istilah teknis",
      "Berhenti sebentar di antara kalimat"
    ],
    'th': [
      "à¸à¸¹à¸”à¸Šà¸±à¸”à¹€à¸ˆà¸™à¹à¸¥à¸°à¸Šà¹‰à¸²à¹†",
      "à¹ƒà¸Šà¹‰à¸à¸²à¸£à¸­à¸­à¸à¹€à¸ªà¸µà¸¢à¸‡à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸¨à¸±à¸à¸—à¹Œà¸—à¸²à¸‡à¹€à¸—à¸„à¸™à¸´à¸„",
      "à¸«à¸¢à¸¸à¸”à¸ªà¸±à¸à¸„à¸£à¸¹à¹ˆà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸›à¸£à¸°à¹‚à¸¢à¸„"
    ],
    'vi': [
      "NÃ³i rÃµ rÃ ng vÃ  cháº­m rÃ£i",
      "Sá»­ dá»¥ng phÃ¡t Ã¢m Ä‘Ãºng cho thuáº­t ngá»¯ ká»¹ thuáº­t",
      "Táº¡m dá»«ng giá»¯a cÃ¡c cÃ¢u"
    ],
    'zh-cn': [
      "è¯´è¯æ¸…æ¥šï¼Œè¯­é€Ÿé€‚ä¸­",
      "ä¸“ä¸šæœ¯è¯­éœ€è¦å‡†ç¡®å‘éŸ³",
      "å¥å­ä¹‹é—´è¦æœ‰çŸ­æš‚åœé¡¿"
    ],
    'zh-tw': [
      "èªªè©±æ¸…æ¥šï¼Œèªé€Ÿé©ä¸­",
      "å°ˆæ¥­è¡“èªéœ€è¦æº–ç¢ºç™¼éŸ³",
      "å¥å­ä¹‹é–“è¦æœ‰çŸ­æš«åœé “"
    ],
    'zh-hk': [
      "è¬›è©±æ¸…æ¥šï¼Œèªé€Ÿé©ä¸­",
      "å°ˆæ¥­è¡“èªéœ€è¦æº–ç¢ºç™¼éŸ³",
      "å¥å­ä¹‹é–“è¦æœ‰çŸ­æš«åœé “"
    ]
  };
  
  const tips = languageTips[language] || languageTips['en'];
  recommendations.push(...tips);
  
  return recommendations;
}

export default router;

