import { Router } from 'express';
import { sealionService } from '../services/sealion';
import { AIService } from '../services/ai-service';
import { requireAuth } from '../middleware/auth-middleware';
import * as multer from 'multer';
import { v4 as uuidv4 } from 'uuid';
import * as path from 'path';
import * as fs from 'fs';

const router = Router();
const upload = multer.default({ 
  dest: 'uploads/',
  limits: { fileSize: 10 * 1024 * 1024 } // 10MB limit
});

// Ensure uploads directory exists
if (!fs.existsSync('uploads')) {
  fs.mkdirSync('uploads', { recursive: true });
}

// Voice service status
router.get('/health', async (req, res) => {
  try {
    const status = {
      status: 'healthy',
      services: {
        sealion: true, // Assuming SeaLion is healthy
        openai: true, // Assuming OpenAI is always available
        whisper: true, // Assuming Whisper is available
        tts: true
      },
      timestamp: new Date().toISOString()
    };
    res.json(status);
  } catch (error) {
    res.status(500).json({ error: 'Voice services health check failed' });
  }
});

// Voice service configuration
router.get('/config', async (req, res) => {
  try {
    const config = {
      supportedLanguages: [
        { code: 'en', name: 'English', localName: 'English' },
        { code: 'ms', name: 'Bahasa Malaysia', localName: 'Bahasa Malaysia' },
        { code: 'id', name: 'Bahasa Indonesia', localName: 'Bahasa Indonesia' },
        { code: 'th', name: 'Thai', localName: 'ไทย' },
        { code: 'vi', name: 'Vietnamese', localName: 'Tiếng Việt' },
        { code: 'fil', name: 'Filipino', localName: 'Filipino' },
        { code: 'my', name: 'Myanmar', localName: 'မြန်မာ' },
        { code: 'km', name: 'Khmer', localName: 'ខ្មែរ' },
        { code: 'lo', name: 'Lao', localName: 'ລາວ' },
        { code: 'zh-sg', name: 'Chinese Singapore', localName: '中文' }
      ],
      ttsVoices: {
        en: ['en-US-Standard-A', 'en-US-Standard-B', 'en-US-Standard-C'],
        ms: ['ms-MY-Standard-A', 'ms-MY-Standard-B'],
        id: ['id-ID-Standard-A', 'id-ID-Standard-B'],
        th: ['th-TH-Standard-A', 'th-TH-Standard-B'],
        vi: ['vi-VN-Standard-A', 'vi-VN-Standard-B']
      },
      sttModels: ['whisper-1', 'whisper-large-v2', 'whisper-large-v3'],
      maxFileSize: '10MB',
      supportedFormats: ['wav', 'mp3', 'm4a', 'webm', 'ogg']
    };
    res.json(config);
  } catch (error) {
    res.status(500).json({ error: 'Failed to get voice configuration' });
  }
});

// Text-to-Speech endpoint
router.post('/tts', requireAuth, async (req, res) => {
  try {
    const { text, language = 'en', voice, rate = 1.0, pitch = 1.0 } = req.body;
    
    if (!text) {
      return res.status(400).json({ error: 'Text is required' });
    }

    // Use SeaLion for text processing and voice selection
    const processedText = await sealionService.generateResponse({
      messages: [{
        role: 'user',
        content: `Process this text for TTS in ${language}: "${text}". 
        Ensure it's properly formatted for speech synthesis. 
        Return only the processed text, no explanations.`
      }],
      maxTokens: 500,
      temperature: 0.3
    });

    // Generate TTS response
    const ttsResponse = {
      success: true,
      text: processedText,
      language,
      voice: voice || getDefaultVoice(language),
      rate,
      pitch,
      duration: estimateDuration(processedText),
      audioUrl: null, // Will be generated by frontend
      timestamp: new Date().toISOString()
    };

    res.json(ttsResponse);
  } catch (error) {
    console.error('TTS Error:', error);
    res.status(500).json({ 
      error: 'TTS generation failed',
      details: error instanceof Error ? error.message : 'Unknown error'
    });
  }
});

// Speech-to-Text endpoint
router.post('/stt', requireAuth, upload.single('audio'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'Audio file is required' });
    }

    const { language = 'en', model = 'whisper-1' } = req.body;
    const audioPath = req.file.path;

    try {
      // For now, return a mock transcription since we don't have OpenAI Whisper API key
      // In production, this would use OpenAI Whisper API
      const mockTranscription = `This is a mock transcription for ${language}. In production, this would use OpenAI Whisper API to transcribe the audio file.`;
      
      // Use SeaLion for post-processing and language correction
      const processedTranscription = await sealionService.generateResponse({
        messages: [{
          role: 'user',
          content: `Correct and improve this transcription in ${language}: "${mockTranscription}". 
          Fix any errors, improve grammar, and ensure it's natural. 
          Return only the corrected text, no explanations.`
        }],
        maxTokens: 500,
        temperature: 0.2
      });

      const sttResponse = {
        success: true,
        transcription: processedTranscription,
        originalTranscription: mockTranscription,
        language,
        model,
        confidence: 0.95, // Placeholder
        duration: req.file.size / 1000, // Rough estimate
        timestamp: new Date().toISOString()
      };

      res.json(sttResponse);
    } finally {
      // Clean up uploaded file
      fs.unlinkSync(audioPath);
    }
  } catch (error) {
    console.error('STT Error:', error);
    res.status(500).json({ 
      error: 'STT processing failed',
      details: error instanceof Error ? error.message : 'Unknown error'
    });
  }
});

// Translation endpoint
router.post('/translate', requireAuth, async (req, res) => {
  try {
    const { text, targetLanguage, sourceLanguage = 'en' } = req.body;
    
    if (!text || !targetLanguage) {
      return res.status(400).json({ error: 'Text and target language are required' });
    }

    // Use SeaLion for translation
    const translation = await sealionService.generateResponse({
      messages: [{
        role: 'user',
        content: `Translate this text from ${sourceLanguage} to ${targetLanguage}: "${text}". 
        Ensure the translation is natural, culturally appropriate, and maintains the original meaning. 
        Return only the translation, no explanations.`
      }],
      maxTokens: 1000,
      temperature: 0.3
    });

    const translationResponse = {
      success: true,
      originalText: text,
      translatedText: translation,
      sourceLanguage,
      targetLanguage,
      timestamp: new Date().toISOString()
    };

    res.json(translationResponse);
  } catch (error) {
    console.error('Translation Error:', error);
    res.status(500).json({ 
      error: 'Translation failed',
      details: error instanceof Error ? error.message : 'Unknown error'
    });
  }
});

// Voice quality analysis
router.post('/analyze-quality', requireAuth, upload.single('audio'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'Audio file is required' });
    }

    const audioPath = req.file.path;
    const audioBuffer = fs.readFileSync(audioPath);
    
    // Basic audio quality analysis
    const qualityAnalysis = {
      volume: analyzeVolume(audioBuffer),
      clarity: analyzeClarity(audioBuffer),
      noise: analyzeNoise(audioBuffer),
      duration: audioBuffer.length / 1000,
      sampleRate: 44100, // Placeholder
      bitRate: 128, // Placeholder
      recommendations: generateQualityRecommendations(audioBuffer)
    };

    res.json({
      success: true,
      quality: qualityAnalysis,
      timestamp: new Date().toISOString()
    });

    // Clean up
    fs.unlinkSync(audioPath);
  } catch (error) {
    console.error('Quality Analysis Error:', error);
    res.status(500).json({ 
      error: 'Quality analysis failed',
      details: error instanceof Error ? error.message : 'Unknown error'
    });
  }
});

// Helper functions
function getDefaultVoice(language: string): string {
  const voiceMap: Record<string, string> = {
    'en': 'en-US-Standard-A',
    'ms': 'ms-MY-Standard-A',
    'id': 'id-ID-Standard-A',
    'th': 'th-TH-Standard-A',
    'vi': 'vi-VN-Standard-A',
    'fil': 'fil-PH-Standard-A',
    'my': 'my-MM-Standard-A',
    'km': 'km-KH-Standard-A',
    'lo': 'lo-LA-Standard-A',
    'zh-sg': 'zh-SG-Standard-A'
  };
  return voiceMap[language] || 'en-US-Standard-A';
}

function estimateDuration(text: string): number {
  // Rough estimate: 150 words per minute
  const words = text.split(' ').length;
  return Math.ceil((words / 150) * 60);
}

function analyzeVolume(audioBuffer: Buffer): number {
  // Basic volume analysis
  let sum = 0;
  for (let i = 0; i < audioBuffer.length; i += 2) {
    const sample = audioBuffer.readInt16LE(i);
    sum += Math.abs(sample);
  }
  return sum / (audioBuffer.length / 2) / 32768;
}

function analyzeClarity(audioBuffer: Buffer): number {
  // Basic clarity analysis (placeholder)
  return 0.8;
}

function analyzeNoise(audioBuffer: Buffer): number {
  // Basic noise analysis (placeholder)
  return 0.1;
}

function generateQualityRecommendations(audioBuffer: Buffer): string[] {
  const recommendations = [];
  const volume = analyzeVolume(audioBuffer);
  
  if (volume < 0.1) {
    recommendations.push("Audio volume is too low. Please speak closer to the microphone.");
  } else if (volume > 0.9) {
    recommendations.push("Audio volume is too high. Please speak further from the microphone.");
  }
  
  if (audioBuffer.length < 1000) {
    recommendations.push("Audio is too short. Please speak for at least 2-3 seconds.");
  }
  
  return recommendations;
}

export default router;
